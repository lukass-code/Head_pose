{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC29H3ffGqw2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U02rl_IIObc"
      },
      "source": [
        "Flip image to get more training data (Aeffectilfe [..] without keypoints)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7jUTLO9Jhao"
      },
      "source": [
        "# Head pose estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9uLuvTTJkfp"
      },
      "source": [
        "Names: Javier Covas Llompart, Lukas Koberg\n",
        "\n",
        "The goal is to develop a neural notwork, that is able to detect the pose of a head (the 3 angles). Therfor pytorch is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avSnsXC8J5Ec"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4pG4l13J9zc",
        "outputId": "ee06b3b9-a762-4357-ad9b-0b77a8e69a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "from torchvision.models import resnet50, resnet152\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "from PIL import Image\n",
        "import scipy.io as sio\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bway4hPFNB3h"
      },
      "outputs": [],
      "source": [
        "basepath = \"Advanced Topics Computer Vision/Short Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "basepath = \"Data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_euler_angles_from_rotation_matrices(rotation_matrices, full_range=False):\n",
        "    batch = rotation_matrices.shape[0]\n",
        "    R = rotation_matrices\n",
        "    sy = torch.sqrt(R[:,0,0]*R[:,0,0]+R[:,1,0]*R[:,1,0])\n",
        "    singular = sy<1e-6\n",
        "    singular = singular.float()\n",
        "\n",
        "    '''2023.01.15'''\n",
        "    for i in range(len(sy)):  # expand y (yaw angle) range into (-180, 180)\n",
        "        if R[i, 0, 0] < 0 and full_range:\n",
        "            sy[i] = -sy[i]\n",
        "\n",
        "    x = torch.atan2(R[:,2,1], R[:,2,2])\n",
        "    y = torch.atan2(-R[:,2,0], sy)\n",
        "    z = torch.atan2(R[:,1,0],R[:,0,0])\n",
        "\n",
        "    xs = torch.atan2(-R[:,1,2], R[:,1,1])\n",
        "    ys = torch.atan2(-R[:,2,0], sy)\n",
        "    zs = R[:,1,0]*0\n",
        "\n",
        "    gpu = rotation_matrices.get_device()\n",
        "    if gpu < 0:\n",
        "        out_euler = torch.autograd.Variable(torch.zeros(batch,3)).to(torch.device('cpu'))\n",
        "    else:\n",
        "        out_euler = torch.autograd.Variable(torch.zeros(batch,3)).to(torch.device('cuda:%d' % gpu))\n",
        "    out_euler[:,0] = x*(1-singular)+xs*singular\n",
        "    out_euler[:,1] = y*(1-singular)+ys*singular\n",
        "    out_euler[:,2] = z*(1-singular)+zs*singular\n",
        "    # print('out_euler', out_euler)\n",
        "\n",
        "    return out_euler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fo81w9dQsfi"
      },
      "source": [
        "## Load Datasets and Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oXf19zOGb3dK"
      },
      "outputs": [],
      "source": [
        "class BIWI_Dataset(Dataset):\n",
        "    def __init__(self): #Example code\n",
        "        # convert into PyTorch tensors and remember them\n",
        "        \n",
        "        self.X = self.read_data()[0]\n",
        "        self.y = self.read_data()[1]\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, train_size=0.7, shuffle=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        # this should return the size of the dataset\n",
        "        return len(self.X_train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # this should return one sample from the dataset\n",
        "        #features = pil_to_tensor(Image.open(self.X[idx])).float()\n",
        "        target_height = 100\n",
        "        img = Image.open(self.X_train[idx])\n",
        "        width, height = img.size\n",
        "        new_width = int(width * (target_height / height))\n",
        "        img = img.resize((new_width, target_height))\n",
        "        features = self.transform(img)\n",
        "        target = self.y_train[idx, 1].unsqueeze(0)\n",
        "        return features, target\n",
        "    \n",
        "    def get_test_item(self, idx):\n",
        "        # this should return one sample from the dataset\n",
        "        #features = pil_to_tensor(Image.open(self.X[idx])).float()\n",
        "        target_height = 50\n",
        "        img = Image.open(self.X_test[idx])\n",
        "        width, height = img.size\n",
        "        new_width = int(width * (target_height / height))\n",
        "        features = self.transform(img)\n",
        "        target = self.y_test[idx, 1]\n",
        "        return features, target\n",
        "    \n",
        "    transform = T.Compose([\n",
        "        #T.ToPILImage(),\n",
        "        #T.Resize(([64, 49])),\n",
        "        T.ToTensor()])\n",
        "    \n",
        "    def read_data(self):\n",
        "        list_angle_data = []\n",
        "        list_picture_data = []\n",
        "\n",
        "        #folder_nr = \"01\"\n",
        "        for i in range(1, 25):\n",
        "            if i <10:\n",
        "                folder_nr = \"0\" + str(i)\n",
        "            else:\n",
        "                folder_nr = str(i)\n",
        "            for file in os.listdir(basepath + \"BIWI/\" + folder_nr):\n",
        "                if file.endswith(\".png\"):\n",
        "                    list_picture_data.append(basepath + \"BIWI/\" + folder_nr + \"/\" + file)\n",
        "                    f = open(basepath + \"BIWI/\" + folder_nr + \"/frame_\" + file.split(\"_\")[1] + \"_pose.txt\", \"r\")\n",
        "                    file_data = f.read()\n",
        "                    file_data_split = file_data.split()\n",
        "                    matrix = np.array(file_data_split[0:9], dtype=np.float32).reshape(3, 3)\n",
        "                    list_angle_data.append(matrix)\n",
        "        #print((np.stack(list_angle_data, axis=0).shape))\n",
        "        angles = compute_euler_angles_from_rotation_matrices(torch.tensor(np.stack(list_angle_data, axis=0), dtype=torch.float32))\n",
        "        #print(angles*180/np.pi)\n",
        "        return list_picture_data, angles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[[0.6157, 0.7529, 0.7529,  ..., 0.5020, 0.5020, 0.4118],\n",
            "         [0.7804, 0.9569, 0.9608,  ..., 0.6078, 0.6118, 0.5020],\n",
            "         [0.8275, 0.9961, 0.9961,  ..., 0.6039, 0.6039, 0.4980],\n",
            "         ...,\n",
            "         [0.0078, 0.0471, 0.1412,  ..., 0.0431, 0.2941, 0.4353],\n",
            "         [0.0196, 0.1020, 0.1647,  ..., 0.0471, 0.3020, 0.4392],\n",
            "         [0.0275, 0.0980, 0.1333,  ..., 0.0431, 0.2549, 0.3608]],\n",
            "\n",
            "        [[0.6118, 0.7490, 0.7451,  ..., 0.4784, 0.4824, 0.3882],\n",
            "         [0.7765, 0.9529, 0.9529,  ..., 0.5882, 0.5882, 0.4745],\n",
            "         [0.8275, 0.9961, 0.9961,  ..., 0.5804, 0.5843, 0.4706],\n",
            "         ...,\n",
            "         [0.0078, 0.0314, 0.0863,  ..., 0.0588, 0.3255, 0.4196],\n",
            "         [0.0118, 0.0627, 0.0902,  ..., 0.0706, 0.3490, 0.4157],\n",
            "         [0.0196, 0.0627, 0.0784,  ..., 0.0510, 0.3020, 0.3373]],\n",
            "\n",
            "        [[0.6196, 0.7608, 0.7569,  ..., 0.4431, 0.4627, 0.3765],\n",
            "         [0.7843, 0.9608, 0.9608,  ..., 0.5569, 0.5725, 0.4627],\n",
            "         [0.8275, 0.9961, 0.9922,  ..., 0.5569, 0.5686, 0.4627],\n",
            "         ...,\n",
            "         [0.0118, 0.0196, 0.0235,  ..., 0.0588, 0.3686, 0.4353],\n",
            "         [0.0118, 0.0275, 0.0392,  ..., 0.0588, 0.3647, 0.4235],\n",
            "         [0.0157, 0.0235, 0.0314,  ..., 0.0667, 0.3216, 0.3529]]]), tensor([0.5273]))\n"
          ]
        }
      ],
      "source": [
        "dataset = BIWI_Dataset()\n",
        "print(dataset.__getitem__(11))\n",
        "#plt.hist(dataset.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([  92.,  278.,  645., 1282., 3006., 2396., 1403., 1005.,  536.,\n",
              "         331.]),\n",
              " array([-1.44111383, -1.20354509, -0.96597642, -0.72840774, -0.49083906,\n",
              "        -0.25327036, -0.01570166,  0.22186702,  0.45943573,  0.69700444,\n",
              "         0.93457311]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(dataset.y_train[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 133, 3])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reshaped_image = dataset.__getitem__(0)[0].permute(1, 2, 0)\n",
        "print(reshaped_image.shape)\n",
        "# Display the image using plt.imshow\n",
        "plt.imshow(reshaped_image)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10974"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset.X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izscGVmqQy1h"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTgXPDHrR86H"
      },
      "source": [
        "- Oroginal paper based on RESNET!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldehqvaHQ0qe",
        "outputId": "ab8e56e7-bfae-44b8-e236-334f4ffe7582"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "e:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─ResNet: 1-1                            [-1, 1000]                --\n",
            "|    └─Conv2d: 2-1                       [-1, 64, 150, 150]        9,408\n",
            "|    └─BatchNorm2d: 2-2                  [-1, 64, 150, 150]        128\n",
            "|    └─ReLU: 2-3                         [-1, 64, 150, 150]        --\n",
            "|    └─MaxPool2d: 2-4                    [-1, 64, 75, 75]          --\n",
            "|    └─Sequential: 2-5                   [-1, 256, 75, 75]         --\n",
            "|    |    └─Bottleneck: 3-1              [-1, 256, 75, 75]         75,008\n",
            "|    |    └─Bottleneck: 3-2              [-1, 256, 75, 75]         70,400\n",
            "|    |    └─Bottleneck: 3-3              [-1, 256, 75, 75]         70,400\n",
            "|    └─Sequential: 2-6                   [-1, 512, 38, 38]         --\n",
            "|    |    └─Bottleneck: 3-4              [-1, 512, 38, 38]         379,392\n",
            "|    |    └─Bottleneck: 3-5              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-6              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-7              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-8              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-9              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-10             [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-11             [-1, 512, 38, 38]         280,064\n",
            "|    └─Sequential: 2-7                   [-1, 1024, 19, 19]        --\n",
            "|    |    └─Bottleneck: 3-12             [-1, 1024, 19, 19]        1,512,448\n",
            "|    |    └─Bottleneck: 3-13             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-14             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-15             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-16             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-17             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-18             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-19             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-20             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-21             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-22             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-23             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-24             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-25             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-26             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-27             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-28             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-29             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-30             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-31             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-32             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-33             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-34             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-35             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-36             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-37             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-38             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-39             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-40             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-41             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-42             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-43             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-44             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-45             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-46             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-47             [-1, 1024, 19, 19]        1,117,184\n",
            "|    └─Sequential: 2-8                   [-1, 2048, 10, 10]        --\n",
            "|    |    └─Bottleneck: 3-48             [-1, 2048, 10, 10]        6,039,552\n",
            "|    |    └─Bottleneck: 3-49             [-1, 2048, 10, 10]        4,462,592\n",
            "|    |    └─Bottleneck: 3-50             [-1, 2048, 10, 10]        4,462,592\n",
            "|    └─AdaptiveAvgPool2d: 2-9            [-1, 2048, 1, 1]          --\n",
            "|    └─Linear: 2-10                      [-1, 1000]                2,049,000\n",
            "├─Flatten: 1-2                           [-1, 1000]                --\n",
            "├─Linear: 1-3                            [-1, 1000]                1,001,000\n",
            "├─ReLU: 1-4                              [-1, 1000]                --\n",
            "├─Linear: 1-5                            [-1, 1000]                1,001,000\n",
            "├─ReLU: 1-6                              [-1, 1000]                --\n",
            "├─Linear: 1-7                            [-1, 500]                 500,500\n",
            "├─ReLU: 1-8                              [-1, 500]                 --\n",
            "├─Linear: 1-9                            [-1, 1]                   501\n",
            "==========================================================================================\n",
            "Total params: 62,695,809\n",
            "Trainable params: 62,695,809\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 20.80\n",
            "==========================================================================================\n",
            "Input size (MB): 1.03\n",
            "Forward/backward pass size (MB): 589.34\n",
            "Params size (MB): 239.17\n",
            "Estimated Total Size (MB): 829.54\n",
            "==========================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─ResNet: 1-1                            [-1, 1000]                --\n",
              "|    └─Conv2d: 2-1                       [-1, 64, 150, 150]        9,408\n",
              "|    └─BatchNorm2d: 2-2                  [-1, 64, 150, 150]        128\n",
              "|    └─ReLU: 2-3                         [-1, 64, 150, 150]        --\n",
              "|    └─MaxPool2d: 2-4                    [-1, 64, 75, 75]          --\n",
              "|    └─Sequential: 2-5                   [-1, 256, 75, 75]         --\n",
              "|    |    └─Bottleneck: 3-1              [-1, 256, 75, 75]         75,008\n",
              "|    |    └─Bottleneck: 3-2              [-1, 256, 75, 75]         70,400\n",
              "|    |    └─Bottleneck: 3-3              [-1, 256, 75, 75]         70,400\n",
              "|    └─Sequential: 2-6                   [-1, 512, 38, 38]         --\n",
              "|    |    └─Bottleneck: 3-4              [-1, 512, 38, 38]         379,392\n",
              "|    |    └─Bottleneck: 3-5              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-6              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-7              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-8              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-9              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-10             [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-11             [-1, 512, 38, 38]         280,064\n",
              "|    └─Sequential: 2-7                   [-1, 1024, 19, 19]        --\n",
              "|    |    └─Bottleneck: 3-12             [-1, 1024, 19, 19]        1,512,448\n",
              "|    |    └─Bottleneck: 3-13             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-14             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-15             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-16             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-17             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-18             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-19             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-20             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-21             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-22             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-23             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-24             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-25             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-26             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-27             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-28             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-29             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-30             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-31             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-32             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-33             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-34             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-35             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-36             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-37             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-38             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-39             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-40             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-41             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-42             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-43             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-44             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-45             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-46             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-47             [-1, 1024, 19, 19]        1,117,184\n",
              "|    └─Sequential: 2-8                   [-1, 2048, 10, 10]        --\n",
              "|    |    └─Bottleneck: 3-48             [-1, 2048, 10, 10]        6,039,552\n",
              "|    |    └─Bottleneck: 3-49             [-1, 2048, 10, 10]        4,462,592\n",
              "|    |    └─Bottleneck: 3-50             [-1, 2048, 10, 10]        4,462,592\n",
              "|    └─AdaptiveAvgPool2d: 2-9            [-1, 2048, 1, 1]          --\n",
              "|    └─Linear: 2-10                      [-1, 1000]                2,049,000\n",
              "├─Flatten: 1-2                           [-1, 1000]                --\n",
              "├─Linear: 1-3                            [-1, 1000]                1,001,000\n",
              "├─ReLU: 1-4                              [-1, 1000]                --\n",
              "├─Linear: 1-5                            [-1, 1000]                1,001,000\n",
              "├─ReLU: 1-6                              [-1, 1000]                --\n",
              "├─Linear: 1-7                            [-1, 500]                 500,500\n",
              "├─ReLU: 1-8                              [-1, 500]                 --\n",
              "├─Linear: 1-9                            [-1, 1]                   501\n",
              "==========================================================================================\n",
              "Total params: 62,695,809\n",
              "Trainable params: 62,695,809\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 20.80\n",
              "==========================================================================================\n",
              "Input size (MB): 1.03\n",
              "Forward/backward pass size (MB): 589.34\n",
              "Params size (MB): 239.17\n",
              "Estimated Total Size (MB): 829.54\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet152_model = resnet152(pretrained=False)\n",
        "class HeadPoseModel_1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet152_model = resnet152_model\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(1000, 1000)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(1000, 1000)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.linear3 = nn.Linear(1000, 500)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.linear4 = nn.Linear(500, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.resnet152_model(x)\n",
        "      x = self.flatten(x)\n",
        "      x = self.act1(self.linear1(x))\n",
        "      x = self.act2(self.linear2(x))\n",
        "      x = self.act3(self.linear3(x))\n",
        "      x = self.linear4(x)\n",
        "      return x\n",
        "\n",
        "model = HeadPoseModel_1()\n",
        "#print(model)\n",
        "summary(model,(3,300,300))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBoPmZ69crKb"
      },
      "source": [
        "## Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "A-KE2gZodSoK"
      },
      "outputs": [],
      "source": [
        "# set up DataLoader for training set\n",
        "dataset = BIWI_Dataset()\n",
        "loader = DataLoader(dataset, shuffle=True, batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uKdem2LAcvBh"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()  # Mean squered error loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nvSAtuJRdC4t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.23586219549179077\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 14.796905517578125\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16134314239025116\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.26758483052253723\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.530124306678772\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.28793713450431824\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.2015015035867691\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16012805700302124\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.19105692207813263\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.22494813799858093\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.2036169022321701\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.253085732460022\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.2954288423061371\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.18662938475608826\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.24554765224456787\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1948477178812027\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.18004482984542847\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1905508190393448\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.20145204663276672\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1551787257194519\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.18782150745391846\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.19839531183242798\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.23819677531719208\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.14406172931194305\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.18815407156944275\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.14641784131526947\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.18990930914878845\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.23459391295909882\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.2447683960199356\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1757119596004486\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.2052851915359497\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.2547968924045563\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.14274442195892334\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.227547287940979\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.20029345154762268\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16847319900989532\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.14691928029060364\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16046267747879028\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.20959234237670898\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.14844262599945068\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.19138601422309875\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16781693696975708\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.13746561110019684\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.15564218163490295\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16093695163726807\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16086135804653168\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.18299530446529388\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1128360778093338\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.11908160150051117\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.14553874731063843\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1537848711013794\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1314687281847\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.11068130284547806\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.10918392241001129\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12151850014925003\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1222631186246872\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.11198756098747253\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12429556250572205\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.15393422544002533\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12641766667366028\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12730661034584045\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.127998948097229\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.10897524654865265\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1643713414669037\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1014961302280426\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.11318166553974152\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12319917976856232\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.13282787799835205\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.09334117919206619\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0841016098856926\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.11022817343473434\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.13663317263126373\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0932098850607872\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1313539296388626\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.138332799077034\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.10185512900352478\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16091714799404144\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.07576929777860641\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12176758050918579\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.28836438059806824\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.14454427361488342\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.16736948490142822\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.18452991545200348\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1625385731458664\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.1359901875257492\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12560102343559265\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.13920356333255768\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.10268449038267136\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.11771035939455032\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.13174323737621307\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12561887502670288\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.08776875585317612\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06934209167957306\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.09056912362575531\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.08362585306167603\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06455090641975403\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.12879472970962524\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06434837728738785\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0679260790348053\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.08060931414365768\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06033932790160179\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06447723507881165\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.10183761268854141\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0817418172955513\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.05315801501274109\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04968645051121712\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06517567485570908\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06950326263904572\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06086423993110657\n",
            "torch.Size([74, 1])\n",
            "torch.Size([74, 1])\n",
            "latest loss 0.038688190281391144\n",
            "Finished epoch 0, latest loss 0.038688190281391144\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.052868396043777466\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.050325773656368256\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.03302149847149849\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.05066360533237457\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06107044219970703\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0401516929268837\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04345650225877762\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04720126464962959\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04413445293903351\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.055275581777095795\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.060541585087776184\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0371217355132103\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04543587565422058\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.07060806453227997\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06508780270814896\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06636680662631989\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.05600758641958237\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.07255422323942184\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.05149591341614723\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.029051385819911957\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.042245082557201385\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.07464513182640076\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.042918119579553604\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.03033851459622383\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.030887160450220108\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.046900052577257156\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04257133603096008\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.035541191697120667\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.026831889525055885\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.07149255275726318\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.05539332330226898\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04387204349040985\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.03483752906322479\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.052141256630420685\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.045093078166246414\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02401180937886238\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04021121934056282\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.09187191724777222\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.06542905420064926\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.053953543305397034\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02145189605653286\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.043231986463069916\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0339951291680336\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.03171274811029434\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.020710311830043793\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.027716051787137985\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.03215013071894646\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02235940843820572\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.021648315712809563\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01707029901444912\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.024398580193519592\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.017447495833039284\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.016945241019129753\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012685246765613556\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012371842749416828\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014134055003523827\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.016666917130351067\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012634478509426117\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.017127124592661858\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.027800463140010834\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013277066871523857\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011858738958835602\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02495673857629299\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.028964193537831306\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012607388198375702\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.019404979422688484\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.016837671399116516\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.04632299765944481\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.021597376093268394\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008439519442617893\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014750517904758453\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011320935562252998\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.024009792134165764\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.029633579775691032\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01446197833865881\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011258507147431374\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.019905196502804756\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012793865986168385\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01621611788868904\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015417265705764294\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.017996162176132202\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011588807217776775\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01572132110595703\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.021517200395464897\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01849319413304329\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.028141655027866364\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013402416370809078\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013127412647008896\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01519328635185957\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008494147099554539\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010643724352121353\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01194339245557785\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009762112982571125\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011367651633918285\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011356978677213192\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009024330414831638\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012347021140158176\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009634550660848618\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010607651434838772\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015414447523653507\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011482703499495983\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010836545377969742\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012751690112054348\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011055498383939266\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013578507117927074\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008798293769359589\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.022357413545250893\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0067626358941197395\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011398281902074814\n",
            "torch.Size([74, 1])\n",
            "torch.Size([74, 1])\n",
            "latest loss 0.011030219495296478\n",
            "Finished epoch 1, latest loss 0.011030219495296478\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0076942769810557365\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008928627707064152\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010751446709036827\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004684689454734325\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005143826827406883\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006795684807002544\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010318463668227196\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.026468491181731224\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009723448194563389\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.023766323924064636\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007286261301487684\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007833313196897507\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01487333420664072\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02554258517920971\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0178034920245409\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006226005032658577\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009802409447729588\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009301196783781052\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014516221359372139\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008857108652591705\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006388061214238405\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010760216973721981\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006135676987469196\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008684591390192509\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014906673692166805\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011387944221496582\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011834900826215744\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005129863508045673\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01352674514055252\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.027202926576137543\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.028672246262431145\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004517341963946819\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00962296687066555\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.020224852487444878\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0077799404971301556\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009848466143012047\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00623402139171958\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003824622603133321\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010793812572956085\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005284707993268967\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0059362431056797504\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0074662198312580585\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006317102815955877\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004105306230485439\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007091461215168238\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004725623410195112\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004433277528733015\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00694611482322216\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006385188549757004\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009170260280370712\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014129293151199818\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009716612286865711\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007581652607768774\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009044765494763851\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00624784454703331\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005662021692842245\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009800011292099953\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004570810589939356\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006021356675773859\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006483829114586115\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007560282479971647\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005698589142411947\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0066927047446370125\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006412510760128498\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00505212415009737\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004836344160139561\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005706289783120155\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01271352544426918\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004108159337192774\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006550163496285677\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006171312183141708\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007275762036442757\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.021070534363389015\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006894990336149931\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008062991313636303\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0053215064108371735\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007679147180169821\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0082474946975708\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007804912514984608\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014301738701760769\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004473026841878891\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007196923717856407\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012388210743665695\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010680846869945526\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007160833105444908\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004779799375683069\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007953710854053497\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0074927788227796555\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008181799203157425\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013707484118640423\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00516667403280735\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009273015893995762\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014897607266902924\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008725007995963097\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003008831525221467\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008930934593081474\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.034444671124219894\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007370756473392248\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008881189860403538\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006950448267161846\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008314522914588451\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004668134264647961\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02933850698173046\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009226973168551922\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013318214565515518\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009963130578398705\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.018615253269672394\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008097444660961628\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.020134320482611656\n",
            "torch.Size([74, 1])\n",
            "torch.Size([74, 1])\n",
            "latest loss 0.05619410425424576\n",
            "Finished epoch 2, latest loss 0.05619410425424576\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.03025836870074272\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014556513167917728\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.024578040465712547\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012860380113124847\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02531149797141552\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011748457327485085\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009308245964348316\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.020822575315833092\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01040317676961422\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.017676103860139847\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011372506618499756\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008270135149359703\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015014457516372204\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.023286310955882072\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01594923622906208\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.021064219996333122\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.019815718755126\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006973994895815849\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010796001181006432\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.017047692090272903\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.019082041457295418\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0160954799503088\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01622776687145233\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01282519195228815\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014738383702933788\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010862967930734158\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004449754487723112\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.025389034301042557\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00827876664698124\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005403035320341587\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0035260492004454136\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006680656224489212\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0051047359593212605\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00835536327213049\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009294417686760426\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004303389228880405\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008594568818807602\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003491318318992853\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007268963847309351\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008268951438367367\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008350064978003502\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004127722233533859\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010649306699633598\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00827919039875269\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005886596627533436\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003334109438583255\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0026798159815371037\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004674950148910284\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010458585806190968\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0049159470945596695\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004522409290075302\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0044325049966573715\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004009528551250696\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.02205611765384674\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008909422904253006\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010240969248116016\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.020756417885422707\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010036899708211422\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007288822904229164\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.002739297691732645\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.018904030323028564\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015115434303879738\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006345437839627266\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009180531837046146\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009543189778923988\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01050623506307602\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0029327147640287876\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004504012409597635\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00566617026925087\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003708220785483718\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011418342590332031\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006332474295049906\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005421190056949854\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006757912691682577\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005691907834261656\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0075994255021214485\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004650778602808714\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00673784501850605\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006004100665450096\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0032374400179833174\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007320446893572807\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00934327021241188\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006233816035091877\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0024519048165529966\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005850604735314846\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004883357789367437\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0037528956308960915\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015389788895845413\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0050960686057806015\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0033487947657704353\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0037470264360308647\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003603407647460699\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005277451127767563\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0072111100889742374\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003170846728608012\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012443960644304752\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004528569057583809\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.002944636158645153\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007372051011770964\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0026544781867414713\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.002981409430503845\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0038522332906723022\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004635725170373917\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010974177159368992\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00488657783716917\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01658206805586815\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010822121985256672\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014670171774923801\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.014533703215420246\n",
            "torch.Size([74, 1])\n",
            "torch.Size([74, 1])\n",
            "latest loss 0.0036226592492312193\n",
            "Finished epoch 3, latest loss 0.0036226592492312193\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.009658711031079292\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.020703857764601707\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004423614591360092\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004767441190779209\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005617262329906225\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015391038730740547\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004175422713160515\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0020810943096876144\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008287258446216583\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010482978075742722\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015298152342438698\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005433449521660805\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011017910204827785\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01316680945456028\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012923509813845158\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.025845689699053764\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01026437059044838\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.015931790694594383\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.027752883732318878\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.018145136535167694\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007430529687553644\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011293684132397175\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008764940313994884\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013508196920156479\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008305151015520096\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00689947884529829\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0059018610045313835\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008021067827939987\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005916574038565159\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005414438433945179\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.013963728211820126\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00465913163498044\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008725429885089397\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00479827169328928\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.002809249795973301\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0036626618821173906\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010184374637901783\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007352123968303204\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011994047090411186\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006950774230062962\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00287222838960588\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005206639878451824\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01477476954460144\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0035578536335378885\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.021208908408880234\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012411070987582207\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0038579432293772697\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010154685005545616\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01054373662918806\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0069432868622243404\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005579611752182245\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.011872961185872555\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008814455941319466\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005270239897072315\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012710608541965485\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00533079681918025\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004530458711087704\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003642846830189228\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007848878391087055\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.001584608224220574\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010540017858147621\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0047098989598453045\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0025902825873345137\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006605787202715874\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00285101355984807\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004687976092100143\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008677993901073933\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007935426197946072\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006323685869574547\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0029532837215811014\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004814782179892063\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0017371587455272675\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004584528971463442\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0038762434851378202\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004392102360725403\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.006054984405636787\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0036222850903868675\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.005530050024390221\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003956678789108992\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004372065886855125\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0021784030832350254\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0045805443078279495\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00437317555770278\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.007181192748248577\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0018182045314460993\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0032916294876486063\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00372812757268548\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0024004539009183645\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.002336909994482994\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0021198063623160124\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.012299735099077225\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.01905808597803116\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003232128219678998\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0033365245908498764\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0023075416684150696\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004770981147885323\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.00720553332939744\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003090593032538891\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0026562109123915434\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.010249011218547821\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.008151349611580372\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.003481033956632018\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004335340112447739\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.002961227670311928\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0032665147446095943\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0291470717638731\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.016230087727308273\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.004863136913627386\n",
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n",
            "latest loss 0.0035564980935305357\n",
            "torch.Size([74, 1])\n",
            "torch.Size([74, 1])\n",
            "latest loss 0.0048491498455405235\n",
            "Finished epoch 4, latest loss 0.0048491498455405235\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 5\n",
        "save_mode_path = \"Models/model_1/model_checkpoint.pth\"\n",
        "model.train()\n",
        "for epoch in range(n_epochs):\n",
        "    for X_batch, y_batch in loader:\n",
        "        #step = (epoch * len(loader)) + i + 1\n",
        "        y_pred = model(X_batch)\n",
        "        print(y_pred.shape)\n",
        "        print(y_batch.shape)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Save the model's state_dict every 1000 steps\n",
        "        #if step % 1000 == 0:\n",
        "        #   pass\n",
        "            #save_mode_path = \"Models/model_1/model_checkpoint.pth\"\n",
        "            #torch.save(model.state_dict(), save_mode_path)\n",
        "        print(f'latest loss {loss}')\n",
        "    #print(f'{epoch}, step: {step}, latest loss {loss}')\n",
        "    torch.save(model.state_dict(), save_mode_path)\n",
        "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
        "\n",
        "#save_mode_path = \"Models/model_1/model_checkpoint.pth\"\n",
        "torch.save(model.state_dict(), save_mode_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl2ypXGCfOL0"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wuSpGGr2fQp6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeadPoseModel_1(\n",
              "  (resnet152_model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (23): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (24): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (25): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (26): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (27): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (28): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (29): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (30): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (31): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (32): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (33): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (34): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (35): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear1): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (act1): ReLU()\n",
              "  (linear2): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (act2): ReLU()\n",
              "  (linear3): Linear(in_features=500, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model = HeadPoseModel_1()\n",
        "# Load the saved state_dict\n",
        "save_mode_path = \"Models/model_1/model_checkpoint.pth\"\n",
        "\n",
        "model.load_state_dict(torch.load(save_mode_path))\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3090]], grad_fn=<AddmmBackward0>) truth: tensor([0.0761])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3225]], grad_fn=<AddmmBackward0>) truth: tensor([-0.6072])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3079]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3001])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3107]], grad_fn=<AddmmBackward0>) truth: tensor([0.0456])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3193]], grad_fn=<AddmmBackward0>) truth: tensor([-0.1878])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3172]], grad_fn=<AddmmBackward0>) truth: tensor([-0.4286])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3074]], grad_fn=<AddmmBackward0>) truth: tensor([-0.4872])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3300]], grad_fn=<AddmmBackward0>) truth: tensor([-0.8886])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3119]], grad_fn=<AddmmBackward0>) truth: tensor([0.2211])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3142]], grad_fn=<AddmmBackward0>) truth: tensor([-0.4044])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3054]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3702])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3118]], grad_fn=<AddmmBackward0>) truth: tensor([-0.2017])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3090]], grad_fn=<AddmmBackward0>) truth: tensor([0.3467])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3104]], grad_fn=<AddmmBackward0>) truth: tensor([0.2106])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3305]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3129])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3134]], grad_fn=<AddmmBackward0>) truth: tensor([-0.0207])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3068]], grad_fn=<AddmmBackward0>) truth: tensor([-0.2489])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3071]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3192])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3671]], grad_fn=<AddmmBackward0>) truth: tensor([-0.7060])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3086]], grad_fn=<AddmmBackward0>) truth: tensor([0.4185])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3761]], grad_fn=<AddmmBackward0>) truth: tensor([-0.4596])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3065]], grad_fn=<AddmmBackward0>) truth: tensor([-0.0209])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3038]], grad_fn=<AddmmBackward0>) truth: tensor([-0.2308])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3166]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3187])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3087]], grad_fn=<AddmmBackward0>) truth: tensor([-0.4273])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3032]], grad_fn=<AddmmBackward0>) truth: tensor([0.5890])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3080]], grad_fn=<AddmmBackward0>) truth: tensor([-0.2602])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3100]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3465])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3023]], grad_fn=<AddmmBackward0>) truth: tensor([-0.0261])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3100]], grad_fn=<AddmmBackward0>) truth: tensor([-0.2200])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3070]], grad_fn=<AddmmBackward0>) truth: tensor([-0.1732])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3055]], grad_fn=<AddmmBackward0>) truth: tensor([-0.1346])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3053]], grad_fn=<AddmmBackward0>) truth: tensor([-0.7851])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3066]], grad_fn=<AddmmBackward0>) truth: tensor([0.2678])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3232]], grad_fn=<AddmmBackward0>) truth: tensor([-0.2575])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3096]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3581])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3190]], grad_fn=<AddmmBackward0>) truth: tensor([-1.1306])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3082]], grad_fn=<AddmmBackward0>) truth: tensor([-0.4486])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3787]], grad_fn=<AddmmBackward0>) truth: tensor([-0.4294])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3438]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3498])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3096]], grad_fn=<AddmmBackward0>) truth: tensor([-0.5686])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3002]], grad_fn=<AddmmBackward0>) truth: tensor([0.3343])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3082]], grad_fn=<AddmmBackward0>) truth: tensor([0.4368])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3090]], grad_fn=<AddmmBackward0>) truth: tensor([0.7702])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3069]], grad_fn=<AddmmBackward0>) truth: tensor([-1.0454])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3234]], grad_fn=<AddmmBackward0>) truth: tensor([-0.6710])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3029]], grad_fn=<AddmmBackward0>) truth: tensor([-0.0048])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3136]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3551])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3101]], grad_fn=<AddmmBackward0>) truth: tensor([-0.5707])\n",
            "Model accuracy: 0.00%\n",
            "tensor([[-0.3203]], grad_fn=<AddmmBackward0>) truth: tensor([-0.3107])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_test_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m  dataset\u001b[38;5;241m.\u001b[39mget_test_item(i)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m     acc \u001b[38;5;241m=\u001b[39m (y_pred\u001b[38;5;241m.\u001b[39mround() \u001b[38;5;241m==\u001b[39m y_test)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[27], line 16\u001b[0m, in \u001b[0;36mHeadPoseModel_1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet152_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m     18\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(x))\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torchvision\\models\\resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torchvision\\models\\resnet.py:150\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m    148\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m--> 150\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in range(0,100):\n",
        "    y_pred = model(dataset.get_test_item(i)[0].unsqueeze(0))\n",
        "    y_test =  dataset.get_test_item(i)[1].unsqueeze(0)\n",
        "    acc = (y_pred.round() == y_test).float().mean()\n",
        "    acc = float(acc)\n",
        "    print(\"Model accuracy: %.2f%%\" % (acc*100))\n",
        "    print(f\"{y_pred} truth: {y_test}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
