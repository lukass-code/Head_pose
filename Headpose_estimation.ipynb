{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC29H3ffGqw2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U02rl_IIObc"
      },
      "source": [
        "Flip image to get more training data (Aeffectilfe [..] without keypoints)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7jUTLO9Jhao"
      },
      "source": [
        "# Head pose estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9uLuvTTJkfp"
      },
      "source": [
        "Names: Javier Covas Llompart, Lukas Koberg\n",
        "\n",
        "The goal is to develop a neural notwork, that is able to detect the pose of a head (the 3 angles). Therfor pytorch is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avSnsXC8J5Ec"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4pG4l13J9zc",
        "outputId": "ee06b3b9-a762-4357-ad9b-0b77a8e69a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "from torchvision.models import resnet50, resnet152\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "import re\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bway4hPFNB3h"
      },
      "outputs": [],
      "source": [
        "basepath = \"Advanced Topics Computer Vision/Short Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "basepath = \"Data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_euler_angles_from_rotation_matrices(rotation_matrices, full_range=False):\n",
        "    batch = rotation_matrices.shape[0]\n",
        "    R = rotation_matrices\n",
        "    sy = torch.sqrt(R[:,0,0]*R[:,0,0]+R[:,1,0]*R[:,1,0])\n",
        "    singular = sy<1e-6\n",
        "    singular = singular.float()\n",
        "\n",
        "    '''2023.01.15'''\n",
        "    for i in range(len(sy)):  # expand y (yaw angle) range into (-180, 180)\n",
        "        if R[i, 0, 0] < 0 and full_range:\n",
        "            sy[i] = -sy[i]\n",
        "\n",
        "    x = torch.atan2(R[:,2,1], R[:,2,2])\n",
        "    y = torch.atan2(-R[:,2,0], sy)\n",
        "    z = torch.atan2(R[:,1,0],R[:,0,0])\n",
        "\n",
        "    xs = torch.atan2(-R[:,1,2], R[:,1,1])\n",
        "    ys = torch.atan2(-R[:,2,0], sy)\n",
        "    zs = R[:,1,0]*0\n",
        "\n",
        "    gpu = rotation_matrices.get_device()\n",
        "    if gpu < 0:\n",
        "        out_euler = torch.autograd.Variable(torch.zeros(batch,3)).to(torch.device('cpu'))\n",
        "    else:\n",
        "        out_euler = torch.autograd.Variable(torch.zeros(batch,3)).to(torch.device('cuda:%d' % gpu))\n",
        "    out_euler[:,0] = x*(1-singular)+xs*singular\n",
        "    out_euler[:,1] = y*(1-singular)+ys*singular\n",
        "    out_euler[:,2] = z*(1-singular)+zs*singular\n",
        "    # print('out_euler', out_euler)\n",
        "\n",
        "    return out_euler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fo81w9dQsfi"
      },
      "source": [
        "## Load Datasets and Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "oXf19zOGb3dK"
      },
      "outputs": [],
      "source": [
        "class BIWI_Dataset(Dataset):\n",
        "    def __init__(self): #Example code\n",
        "        # convert into PyTorch tensors and remember them\n",
        "        \n",
        "        self.X = self.read_data()[0]\n",
        "        self.y = self.read_data()[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        # this should return the size of the dataset\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # this should return one sample from the dataset\n",
        "        #features = pil_to_tensor(Image.open(self.X[idx])).float()\n",
        "        img_arr = np.array(Image.open(self.X[idx]))\n",
        "        data = img_arr.astype(np.float64)\n",
        "        data = 255 * data\n",
        "        #img_arr = data.astype(np.uint8)\n",
        "        features = self.transform(img_arr)\n",
        "        target = self.y[idx, 0]\n",
        "        return features, target\n",
        "    \n",
        "    transform = T.Compose([\n",
        "        T.ToPILImage(),\n",
        "        T.Resize(([64, 49])),\n",
        "        T.ToTensor()])\n",
        "    \n",
        "    def read_data(self):\n",
        "        list_angle_data = []\n",
        "        list_picture_data = []\n",
        "\n",
        "        #folder_nr = \"01\"\n",
        "        for i in range(1, 2):\n",
        "            if i <10:\n",
        "                folder_nr = \"0\" + str(i)\n",
        "            else:\n",
        "                folder_nr = str(i)\n",
        "            for file in os.listdir(basepath + \"BIWI/\" + folder_nr):\n",
        "                if file.endswith(\".png\"):\n",
        "                    list_picture_data.append(basepath + \"BIWI/\" + folder_nr + \"/\" + file)\n",
        "                    f = open(basepath + \"BIWI/\" + folder_nr + \"/frame_\" + file.split(\"_\")[1] + \"_pose.txt\", \"r\")\n",
        "                    file_data = f.read()\n",
        "                    file_data_split = file_data.split()\n",
        "                    matrix = np.array(file_data_split[0:9], dtype=np.float32).reshape(3, 3)\n",
        "                    list_angle_data.append(matrix)\n",
        "        #print((np.stack(list_angle_data, axis=0).shape))\n",
        "        angles = compute_euler_angles_from_rotation_matrices(torch.tensor(np.stack(list_angle_data, axis=0), dtype=torch.float32))\n",
        "        #print(angles*180/np.pi)\n",
        "        return list_picture_data, angles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[[0.7333, 0.7961, 0.8196,  ..., 0.5373, 0.5255, 0.4902],\n",
            "         [0.8824, 0.9529, 0.9725,  ..., 0.5922, 0.5804, 0.5412],\n",
            "         [0.8118, 0.8549, 0.8431,  ..., 0.5922, 0.5843, 0.5451],\n",
            "         ...,\n",
            "         [0.3137, 0.3176, 0.3020,  ..., 0.4863, 0.2549, 0.2431],\n",
            "         [0.3373, 0.3529, 0.2824,  ..., 0.4745, 0.2431, 0.2392],\n",
            "         [0.3098, 0.3294, 0.2235,  ..., 0.4275, 0.2118, 0.2196]],\n",
            "\n",
            "        [[0.7255, 0.7843, 0.8118,  ..., 0.5098, 0.5020, 0.4627],\n",
            "         [0.8745, 0.9451, 0.9686,  ..., 0.5686, 0.5569, 0.5176],\n",
            "         [0.8235, 0.8588, 0.8510,  ..., 0.5725, 0.5608, 0.5216],\n",
            "         ...,\n",
            "         [0.2157, 0.2196, 0.2000,  ..., 0.4627, 0.2314, 0.2431],\n",
            "         [0.2588, 0.2667, 0.2078,  ..., 0.4510, 0.2235, 0.2471],\n",
            "         [0.2392, 0.2549, 0.1686,  ..., 0.4039, 0.1961, 0.2314]],\n",
            "\n",
            "        [[0.7176, 0.7804, 0.8078,  ..., 0.4627, 0.4549, 0.4275],\n",
            "         [0.8706, 0.9412, 0.9686,  ..., 0.5176, 0.5098, 0.4824],\n",
            "         [0.8353, 0.8863, 0.8784,  ..., 0.5294, 0.5176, 0.4824],\n",
            "         ...,\n",
            "         [0.0392, 0.0392, 0.0353,  ..., 0.4196, 0.2235, 0.2588],\n",
            "         [0.0824, 0.0784, 0.0627,  ..., 0.4118, 0.2157, 0.2510],\n",
            "         [0.0863, 0.0902, 0.0667,  ..., 0.3608, 0.1765, 0.2196]]]), tensor(-0.1360))\n"
          ]
        }
      ],
      "source": [
        "dataset = BIWI_Dataset()\n",
        "print(dataset.__getitem__(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izscGVmqQy1h"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTgXPDHrR86H"
      },
      "source": [
        "- Oroginal paper based on RESNET!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldehqvaHQ0qe",
        "outputId": "ab8e56e7-bfae-44b8-e236-334f4ffe7582"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "e:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─ResNet: 1-1                            [-1, 1000]                --\n",
            "|    └─Conv2d: 2-1                       [-1, 64, 150, 150]        9,408\n",
            "|    └─BatchNorm2d: 2-2                  [-1, 64, 150, 150]        128\n",
            "|    └─ReLU: 2-3                         [-1, 64, 150, 150]        --\n",
            "|    └─MaxPool2d: 2-4                    [-1, 64, 75, 75]          --\n",
            "|    └─Sequential: 2-5                   [-1, 256, 75, 75]         --\n",
            "|    |    └─Bottleneck: 3-1              [-1, 256, 75, 75]         75,008\n",
            "|    |    └─Bottleneck: 3-2              [-1, 256, 75, 75]         70,400\n",
            "|    |    └─Bottleneck: 3-3              [-1, 256, 75, 75]         70,400\n",
            "|    └─Sequential: 2-6                   [-1, 512, 38, 38]         --\n",
            "|    |    └─Bottleneck: 3-4              [-1, 512, 38, 38]         379,392\n",
            "|    |    └─Bottleneck: 3-5              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-6              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-7              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-8              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-9              [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-10             [-1, 512, 38, 38]         280,064\n",
            "|    |    └─Bottleneck: 3-11             [-1, 512, 38, 38]         280,064\n",
            "|    └─Sequential: 2-7                   [-1, 1024, 19, 19]        --\n",
            "|    |    └─Bottleneck: 3-12             [-1, 1024, 19, 19]        1,512,448\n",
            "|    |    └─Bottleneck: 3-13             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-14             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-15             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-16             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-17             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-18             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-19             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-20             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-21             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-22             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-23             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-24             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-25             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-26             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-27             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-28             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-29             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-30             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-31             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-32             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-33             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-34             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-35             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-36             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-37             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-38             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-39             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-40             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-41             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-42             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-43             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-44             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-45             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-46             [-1, 1024, 19, 19]        1,117,184\n",
            "|    |    └─Bottleneck: 3-47             [-1, 1024, 19, 19]        1,117,184\n",
            "|    └─Sequential: 2-8                   [-1, 2048, 10, 10]        --\n",
            "|    |    └─Bottleneck: 3-48             [-1, 2048, 10, 10]        6,039,552\n",
            "|    |    └─Bottleneck: 3-49             [-1, 2048, 10, 10]        4,462,592\n",
            "|    |    └─Bottleneck: 3-50             [-1, 2048, 10, 10]        4,462,592\n",
            "|    └─AdaptiveAvgPool2d: 2-9            [-1, 2048, 1, 1]          --\n",
            "|    └─Linear: 2-10                      [-1, 1000]                2,049,000\n",
            "├─Flatten: 1-2                           [-1, 1000]                --\n",
            "├─Linear: 1-3                            [-1, 1000]                1,001,000\n",
            "├─ReLU: 1-4                              [-1, 1000]                --\n",
            "├─Linear: 1-5                            [-1, 500]                 500,500\n",
            "├─ReLU: 1-6                              [-1, 500]                 --\n",
            "├─Linear: 1-7                            [-1, 1]                   501\n",
            "==========================================================================================\n",
            "Total params: 61,694,809\n",
            "Trainable params: 61,694,809\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 20.80\n",
            "==========================================================================================\n",
            "Input size (MB): 1.03\n",
            "Forward/backward pass size (MB): 589.34\n",
            "Params size (MB): 235.35\n",
            "Estimated Total Size (MB): 825.71\n",
            "==========================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─ResNet: 1-1                            [-1, 1000]                --\n",
              "|    └─Conv2d: 2-1                       [-1, 64, 150, 150]        9,408\n",
              "|    └─BatchNorm2d: 2-2                  [-1, 64, 150, 150]        128\n",
              "|    └─ReLU: 2-3                         [-1, 64, 150, 150]        --\n",
              "|    └─MaxPool2d: 2-4                    [-1, 64, 75, 75]          --\n",
              "|    └─Sequential: 2-5                   [-1, 256, 75, 75]         --\n",
              "|    |    └─Bottleneck: 3-1              [-1, 256, 75, 75]         75,008\n",
              "|    |    └─Bottleneck: 3-2              [-1, 256, 75, 75]         70,400\n",
              "|    |    └─Bottleneck: 3-3              [-1, 256, 75, 75]         70,400\n",
              "|    └─Sequential: 2-6                   [-1, 512, 38, 38]         --\n",
              "|    |    └─Bottleneck: 3-4              [-1, 512, 38, 38]         379,392\n",
              "|    |    └─Bottleneck: 3-5              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-6              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-7              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-8              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-9              [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-10             [-1, 512, 38, 38]         280,064\n",
              "|    |    └─Bottleneck: 3-11             [-1, 512, 38, 38]         280,064\n",
              "|    └─Sequential: 2-7                   [-1, 1024, 19, 19]        --\n",
              "|    |    └─Bottleneck: 3-12             [-1, 1024, 19, 19]        1,512,448\n",
              "|    |    └─Bottleneck: 3-13             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-14             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-15             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-16             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-17             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-18             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-19             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-20             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-21             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-22             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-23             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-24             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-25             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-26             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-27             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-28             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-29             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-30             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-31             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-32             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-33             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-34             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-35             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-36             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-37             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-38             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-39             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-40             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-41             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-42             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-43             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-44             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-45             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-46             [-1, 1024, 19, 19]        1,117,184\n",
              "|    |    └─Bottleneck: 3-47             [-1, 1024, 19, 19]        1,117,184\n",
              "|    └─Sequential: 2-8                   [-1, 2048, 10, 10]        --\n",
              "|    |    └─Bottleneck: 3-48             [-1, 2048, 10, 10]        6,039,552\n",
              "|    |    └─Bottleneck: 3-49             [-1, 2048, 10, 10]        4,462,592\n",
              "|    |    └─Bottleneck: 3-50             [-1, 2048, 10, 10]        4,462,592\n",
              "|    └─AdaptiveAvgPool2d: 2-9            [-1, 2048, 1, 1]          --\n",
              "|    └─Linear: 2-10                      [-1, 1000]                2,049,000\n",
              "├─Flatten: 1-2                           [-1, 1000]                --\n",
              "├─Linear: 1-3                            [-1, 1000]                1,001,000\n",
              "├─ReLU: 1-4                              [-1, 1000]                --\n",
              "├─Linear: 1-5                            [-1, 500]                 500,500\n",
              "├─ReLU: 1-6                              [-1, 500]                 --\n",
              "├─Linear: 1-7                            [-1, 1]                   501\n",
              "==========================================================================================\n",
              "Total params: 61,694,809\n",
              "Trainable params: 61,694,809\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 20.80\n",
              "==========================================================================================\n",
              "Input size (MB): 1.03\n",
              "Forward/backward pass size (MB): 589.34\n",
              "Params size (MB): 235.35\n",
              "Estimated Total Size (MB): 825.71\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet152_model = resnet152(pretrained=False)\n",
        "class HeadPoseModel_1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet152_model = resnet152_model\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(1000, 1000)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(1000, 500)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.linear3 = nn.Linear(500, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.resnet152_model(x)\n",
        "      x = self.flatten(x)\n",
        "      x = self.act1(self.linear1(x))\n",
        "      x = self.act2(self.linear2(x))\n",
        "      x = self.linear3(x)\n",
        "      return x\n",
        "\n",
        "model = HeadPoseModel_1()\n",
        "#print(model)\n",
        "summary(model,(3,300,300))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBoPmZ69crKb"
      },
      "source": [
        "## Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "A-KE2gZodSoK"
      },
      "outputs": [],
      "source": [
        "# set up DataLoader for training set\n",
        "dataset = BIWI_Dataset()\n",
        "loader = DataLoader(dataset, shuffle=True, batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uKdem2LAcvBh"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()  # Mean squered error loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "nvSAtuJRdC4t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "e:\\Programme\\.conda\\envs\\CV_Head\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([99])) that is different to the input size (torch.Size([99, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0, step: 5, latest loss 0.6118510365486145\n",
            "Finished epoch 0, latest loss 0.6118510365486145\n",
            "1, step: 10, latest loss 0.42222583293914795\n",
            "Finished epoch 1, latest loss 0.42222583293914795\n",
            "2, step: 15, latest loss 0.2352713793516159\n",
            "Finished epoch 2, latest loss 0.2352713793516159\n",
            "3, step: 20, latest loss 0.25638386607170105\n",
            "Finished epoch 3, latest loss 0.25638386607170105\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (X_batch, y_batch) in enumerate(loader):\n",
        "        step = (epoch * len(loader)) + i + 1\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Save the model's state_dict every 1000 steps\n",
        "        if step % 1000 == 0:\n",
        "            save_mode_path = basepath + \"/Models/model_1/model_checkpoint.pth\"\n",
        "            torch.save(model.state_dict(), save_mode_path)\n",
        "    print(f'{epoch}, step: {step}, latest loss {loss}')\n",
        "\n",
        "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
        "\n",
        "save_mode_path = basepath + \"/Models/model_1/model_checkpoint.pth\"\n",
        "torch.save(model.state_dict(), save_mode_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl2ypXGCfOL0"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuSpGGr2fQp6"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "# Load the saved state_dict\n",
        "model.load_state_dict(torch.load(\"path/to/save/model_checkpoint.pth\"))\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
